age_grid <- seq(from = age_range[1], to = age_range[2])
age_grid
predict <- predict(lm_1, newdata = list(age = age_grid), se = T)
predict
names(predict)
se_bands <- cbind(predict$fit + 2*predict$se.fit,
predict$fit - 2*predict$se.fit)
se_bands
plot(age, wage)
plot(wage$age, wage$wage)
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5)
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5,
col = 'darkgrey')
title('Degree-4 polynomial', outer = T)
lines(age_grid, predict$fit, lwd = 2, col = 'blue')
matlines(age_grid, se_bands, lwd = 1, col = 'blue', lty = 3)
par(mar = c(4.5, 4.5, 1, 1))
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5,
col = 'darkgrey')
title('Degree-4 polynomial', outer = T)
par(mar = c(4.5, 4, 1, 1))
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5,
col = 'darkgrey')
par(mar = c(4.5, 4.5, 1.5, 1))
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5,
col = 'darkgrey')
title('Degree-4 polynomial', outer = T)
par(mar = c(4.5, 4.5, 1, 1), oma = c(0, 0, 4, 0))
plot(wage$age, wage$wage, xlim = age_range, cex = 0.5,
col = 'darkgrey')
title('Degree-4 polynomial', outer = T)
lines(age_grid, predict$fit, lwd = 2, col = 'blue')
matlines(age_grid, se_bands, lwd = 1, col = 'blue', lty = 3)
predict_2 <- predict(lm_2, newdata = list(age = age_grid), se = T)
max(abs(predict_2$fit - predict$fit))
fit_1 <- lm(wage ~ age, data = Wage)
fit_2 <- lm(wage ~ poly(age, 2), data = Wage)
fit_2 <- lm(wage ~ poly(age, 3), data = Wage)
fit_2 <- lm(wage ~ poly(age, 4), data = Wage)
fit_1 <- lm(wage ~ age, data = Wage)
fit_2 <- lm(wage ~ poly(age, 2), data = Wage)
fit_3 <- lm(wage ~ poly(age, 3), data = Wage)
fit_4 <- lm(wage ~ poly(age, 4), data = Wage)
fit_5 <- lm(wage ~ poly(age, 5), data = Wage)
aov(fit_1, fit_2, fit_3, fit_4, fit_5)
anova(fit_1, fit_2, fit_3, fit_4, fit_5)
coef(summary(fit_5))
fit_6 <- lm(wage ~ education + age, data = wage)
fit_7 <- lm(wage ~ education + poly(age, 2), data = wage)
fit_8 <- lm(wage ~ education + poly(age, 3), data = wage)
anova(fit_6, fit_7, fit_8)
glm <- glm(I(wage > 250) ~ poly(age, 4), data = wage,
family = 'binomial')
glm_predication <- predict(glm, newdata = list(age = age_grid),
se = T)
p_glm <- exp(glm_predication$fit)/(1 + exp(glm_predication$fit))
gp <- glm_predication$fit
ps <- glm_predication$se.fit
se_bands_logits <- cbind(gp + 2*ps, gp - 2*ps)
se_bands <- exp(se_bands_logits)/(1 + exp(se_bands_logits))
preds <- predict(glm, newdata = list(age = age_grid),
type = 'response', se = T)
se_bands
preds
plot(wage$age, I(wage$wage > 250), xlim = age_range,
type = 'n', ylim = c(0, 0.2))
plot(wage$age, I(wage$wage > 250))
plot(wage$age, I(wage$wage > 250), xlim = age_range,
type = 'n', ylim = c(0, 0.2))
install.packages('splines')
install.packages('splines', dependencies = T)
help(package=splines)
spline <- lm(wage ~ bs(age, knots = c(25, 40, 60)), data = wage)
install.packages("~/Downloads/R/splines_2.0-7.tar.gz", repos = NULL, type = "source")
spline <- lm(wage ~ bs(age, knots = c(25, 40, 60)), data = wage)
?bs
??bs
library(splines)
spline <- lm(wage ~ bs(age, knots = c(25, 40, 60)), data = wage)
predict <- predict(spline, newdata = list(age = age_grid), se = T)
plot(age, wage, col = 'gray')
plot(wage$age, wage$wage, col = 'gray')
lines(age_grid, predict$fit, lwd = 2)
lines(age_grid, predict$fit + 2*predict$se.fit, lty = 'dashed')
lines(age_grid, predict$fit - 2*predict$se.fit, lty = 'dashed')
dim(bs(wage$age, knots = c(25, 40, 60)))
dim(bs(wage$age, df = 6))
attr(bs(wage$age, df = 6), 'knots')
spline_2 <- lm(wage ~ ns(age, df = 4), data = wage)
predict_2 <- predict(spline_2, newdata = list(age = age_grid),
se = T)
plot(wage$age, wage$wage, col = 'gray')
lines(age_grid, predict_2$fit, col = 'red', lwd = 2)
lines(age_grid, predict_2$fit + 2*predict_2$se.fit,
lty = 'dashed')
lines(age_grid, predict_2$fit - 2*predict_2$se.fit,
lty = 'dashed')
smooth_spline <- smooth.spline(wage$age, wage$age, df = 16)
smooth_spline <- smooth.spline(wage$age, wage$wage, df = 16)
smooth_spline_2 <- smooth.spline(wage$age, wage$wage, cv = T)
plot(wage$age, wage$wage, col = 'gray')
lines(age_grid, smooth_spline$fit, col = 'red', lwd = 2)
lines(smooth_spline$fit, col = 'red', lwd = 2)
smooth_spline
smooth_spline_2
lines(smooth_spline, col = 'red', lwd = 2)
lines(smooth_spline_2, col = 'blue', lwd = 2)
legend('topright', legend = c('16 DF', '6.8 DF'),
col = c('red', 'blue'), lty = 1, lwd = 2, cex = 0.8)
local <- loess(wage ~ age, span = 0.2, data = wage)
local_2 <- loess(wage ~ age, span = 0.5, data = wage)
plot(wage$age, wage$wage, col = 'gray')
lines(age_grid, predict(local, data.frame(age = age_grid)),
col = 'red', lwd = 2)
lines(age_grid, predict(local_2, data.frame(age = age_grid)),
col = 'red', lwd = 2)
lines(age_grid, predict(local_2, data.frame(age = age_grid)),
col = 'blue', lwd = 2)
legend('topright', legend = c('Span = 0.2', 'Span = 0.5'),
col = c('red', 'blue'), lty = 1, lwd = 2, cex = 0.8)
lm_1 <- lm(wage ~ ns(year, 4) + ns(age, 5) + education,
data = wage)
lm_1
library(gam)
install.packages('gam')
library(gam)
gam <- gam(wage ~ s(year, 4) + s(age, 5) + education,
data = wage)
par(mfrow = c(1, 3))
plot(gam, se = T, col = 'blue')
plot.gam(gam, se = T, col = 'red')
gam_1 <- gam(wage ~ s(age, 5) + education, data = wage)
gam_2 <- gam(wage ~ year + s(age, 5) + education, data = wage)
anova(gam, gam_1, gam_2, test = 'F')
summary(gam)
gam_predict <- predict(gam_2, newdata = wage)
gam_local <- gam(wage ~ s(year, df = 4) + lo(year, span = 0.7),
+ education, data = wage)
gam_local <- gam(wage ~ s(year, df = 4) + lo(year, span = 0.7)
+ education, data = wage)
plot(gam_local, se = T, col = 'green')
gam_local <- gam(wage ~ s(year, df = 4) + lo(age, span = 0.7)
+ education, data = wage)
plot(gam_local, se = T, col = 'green')
gam_local_inter <- gam(wage ~ lo(year, age, span = 0.5) +
education, data = wage)
plot(gam_local_inter, se = T, col = 'green')
plot.gam(gam_local_inter, se = T, col = 'green')
library(akima)
install.packages('akima')
library(akima)
plot.gam(gam_local_inter, se = T, col = 'green')
plot.gam(gam_local_inter)
gam_lr <- gam(I(wage > 250) ~ year + s(age, df = 5) + education,
family = binomial, data = wage)
par(mfrow = c(1, 3))
plot(gam_lr, se = T, col = 'green')
table(education, I(wage > 250))
table(wage$education, I(wage$wage > 250))
gam_lr <- gam(I(wage > 250) ~ year + s(age, df = 5) + education,
family = binomial, data = wage,
subset = (education != '1. < HS Grad'))
par(mfrow = c(1, 3))
plot(gam_lr, se = T, col = 'green')
library(tree)
install.packages('tree')
library(tree)
carseats <- Carseats
high <- ifelse(carseats$Sales <= 8, 'No', 'Yes')
head(carseats)
carseats <- data.frame(carseats, high)
head(carseats)
tree <- tree(high ~ . - Sales, carseats)
summary(tree)
plot(tree)
text(carseats, pretty= 0)
text(tree, pretty = 0)
tree
set.seed(138)
train <- sample(1:nrow(carseats), 200)
carseats_train <- carseats[train, ]
carseats_test <- carseats[-train, ]
high_test <- high[-train]
tree_2 <- tree(high ~ . -Sales, data = carseats, subset = train)
tree_pred <- predict(tree_2, carseats_test, type = 'class')
table(tree_pred, high_test)
(90 + 60)/200
set.seed(135)
cv_tree <- cv.tree(tree_2, FUN = prune.misclass)
names(cv_tree)
cv_tree
par(mfrow = c(1, 2))
plot(cv_tree$size, cv_tree$dev, type = 'b')
plot(cv_tree$k, cv_tree$dev, type = 'b')
prune <- prune.misclass(cv_tree, best = 9)
prune <- prune.misclass(tree_2, best = 9)
plot(prune)
text(prune, pretty = 0)
tree_pred_2 <- predict(prune, carseats_test, type = 'class')
table(tree_pred_2, high_test)
(86 + 63)/200
prune_2 <- prune.misclass(tree_pred_2, best = 15)
prune_2 <- prune.misclass(tree_pred_2, best = 15)
prune_2 <- prune.misclass(tree_2, best = 15)
plot(prune_2)
plot(prune_2)
text(prune_2, pretty = 0)
tree_pred_3 <- predict(prune, carseats_test, type = 'class')
table(tree_pred_3, high_test)
(86 + 63)/200
library(MASS)
set.seed(2536)
train <- sample(1: nrow(Boston), nrow(Boston)/2)
tree_boston <- tree(medv ~ ., Boston, subset = train)
summary(tree_boston)
plot(tree_boston)
text(tree_boston)
text(tree_boston, pretty = 0)
set.seed(536)
train <- sample(1: nrow(Boston), nrow(Boston)/2)
tree_boston <- tree(medv ~ ., Boston, subset = train)
summary(tree_boston)
plot(tree_boston)
text(tree_boston, pretty = 0)
cv_tree_boston <- cv.tree(tree_boston)
cv_tree_boston
par(mfrow = c(1, 2))
plot(cv_tree_boston$size, cv_tree_boston$dev)
plot(cv_tree_boston$size, cv_tree_boston$dev, type = 'b')
plot(cv_tree_boston$size, cv_tree_boston$dev, type = 'b')
par(mfrow = c(1, 2))
plot(cv_tree_boston$size, cv_tree_boston$dev, type = 'b')
plot(cv_tree_boston$k, cv_tree_boston$dev, type = 'b')
prune_boston <- prune.misclass(tree_boston, best = 5)
prune_boston <- prune.tree(tree_boston, best = 5)
plot(prune_boston)
text(prune_boston, best = 0)
boston_pred <- predict(tree_boston, newdata = Boston[-train, ])
boston_test <- Boston$medv[-train]
table(boston_pred, boston_test)
plot(boston_pred, boston_test)
plot(boston_pred, boston_test)
abline(0, 1)
mean((boston_pred - boston_test)^2)
library(randomForest)
set.seed(26)
bag_boston <- randomForest(medv ~ ., data = Boston,
subset = train, mtry = 13,
importance = T)
bag_boston
bag_pred <- predict(bag_boston, Boston[-train, ])
plot(bag_pred, Boston$medv[-train])
abline(0, 1)
mean((bag_pred - Boston$medv[-train])^2)
bag_boston <- randomForest(medv ~ ., data = Boston, subset = train,
mtry = 13, ntree = 25)
bag_boston_2 <- randomForest(medv ~ ., data = Boston, subset = train,
mtry = 13, ntree = 25)
bag_pred_2 <- predict(bag_boston_2, Boston[-train, ])
mean((bag_boston_2 - Boston$medv[-train])^2)
mean((bag_boston_2 - Boston$medv[-train])^2)
bag_boston_2
bag_pred_2 <- predict(bag_boston_2, newdata = Boston[-train, ])
bag_boston_2
mean((bag_boston_2 - Boston$medv[-train])^2)
set.seed(675)
forest_boston <- predict(medv ~ ., data = Boston, subset = train,
mtry = 6, importance = T)
forest_boston <- randomForest(medv ~ ., data = Boston,
subset = train, mtry = 6,
importance = T)
forest_boston_pred <- predict(forest_boston,
newdata = Boston[-train, ])
mean((forest_boston_pred - Boston$medv[-train])^2)
mean((bag_pred_2 - Boston$medv[-train])^2)
importance(forest_boston)
varImpPlot(forest_boston)
library(gbm)
install.packages('gbm')
set.seed(7654)
library(gbm)
boost_boston <- gbm(medv ~ ., data = Boston[train, ],
distribution = 'gaussian',
n.trees = 5000, interaction.depth = 4)
boost_boston
summary(boost_boston)
par(mfrow = c(1, 2))
plot(boost_boston, i = 'rm')
plot(boost_boston, i = 'lstat')
boost_boston_pred <- predict(boost_boston, Boston[-train, ],
n.trees = 5000)
mean((boost_boston_pred - Boston$medv[-train])^2)
boost_boston <- gbm(medv ~ ., data = Boston[train, ],
distribution = 'gaussian',
n.trees = 5000, interaction.depth = 4,
shrinkage = 0.2, verbose = F)
boost_boston_2 <- gbm(medv ~ ., data = Boston[train, ],
distribution = 'gaussian',
n.trees = 5000, interaction.depth = 4,
shrinkage = 0.2, verbose = F)
boost_boston_pred_2 <- predict(boost_boston_2, Boston[-train, ],
n.trees = 5000)
mean((boost_boston_pred_2 - Boston$medv[-train])^2)
library(e1071)
set.seed(1)
x <- matrix(rnorm(20*2), ncol = 2)
x
y <- c(rep(-1, 10), rep(1, 10))
y
x[y == 1, ] = x[y == 1, ] + 1
x
plot(x)
plot(x, col = (3 - y))
plot(x, col = (3 - y))
df <- data.frame(x = x, y = as.factor(y))
df
svm <- svm(y ~ ., data = df, kernel = 'linear', cost = 10,
scale = F)
svm
plot(svm, df)
names(svm)
svm$index
summary(svm)
svm_2 <- svm(y ~ ., data = df, kernel = 'linear', cost = 0.1,
scale = F)
plot(svm_2, df)
summary(svm_2)
svm_2$index
set.seed(27)
tune <- tune(svm, y ~ ., data = df, kernel = 'linear',
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune <- tune(svm_2, y ~ ., data = df, kernel = 'linear',
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune <- tune(svm, y ~ ., data = df,
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
obj3 <- tune.rpart(mpg~., data = mtcars, minsplit = c(5,10,15))
obj <- tune.svm(Species~., data = iris, gamma = 2^(-1:1), cost = 2^(2:4))
rm(list = ls())
library(e1071)
set.seed(1)
x <- matrix(rnorm(20*2), ncol = 2)
y <- c(rep(-1, 10), rep(1, 10))
x[y == 1, ] = x[y == 1, ] + 1
df <- data.frame(x = x, y = as.factor(y))
tune <- tune(svm, y ~ ., data = df,
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
tune
tune <- tune(svm, y ~ ., data = df, kernel = 'linear',
ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))
summary(tune)
best_model <- tune$best.model
summary(best_model)
set.seed(54)
xtest <- matrix(rnorm(20*2), ncol = 2)
ytest <- sample(c(-1, 1), 20, rep = T)
xtest[ytest == 1, ] = xtest[ytest == 1, ] + 1
df_test <- data.frame(x = xtest, y = as.factor(ytest))
predict <- predict(best_model, df_test)
table(predict, df_test$y)
svm_2 <- svm(y ~ ., data = df, kernel = 'linear', cost = 0.01,
scale = T)
predict_2 <- predict(svm_2, df_test)
table(predict_2, df_test$y)
x[y == 1, ] = x[y == 1, ] + 0.5
plot(x, col = (y + 5)/2, pch = T)
plot(x, col = (y + 5)/2, pch = 19)
df_2 <- data.frame(x = x, y = as.factor(y))
df_3 <- data.frame(x = x, y = as.factor(y))
svm_3 <- svm(y ~ ., data = df_3, kernel = 'linear', cost = 1e5)
summary(svm_3)
plot(df_3, svm_3)
plot(svm_3, df_3)
svm_4 <- svm(y ~ ., data = df_3, kernel = 'linear', cost = 1)
summary(svm_4)
plot(svm_4, df_3)
set.seed(26)
x = matrix(rnorm(200*2), ncol = 2)
x[1: 100, ] = x[1:100, ] + 2
x[101: 150, ] = x[101: 150, ] + 2
y <- c(rep(1, 150), rep(2, 150))
df <- data.frame(x, as.factor(y))
y <- c(rep(1, 150), rep(2, 50))
df <- data.frame(x, as.factor(y))
plot(x, col = y)
train <- sample(200, 100)
svm <- svm(y ~ ., data = df[train, ], kernel = 'radical',
gamma = 1, cost = 1)
svm <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1)
plot(x, col = y)
train <- sample(200, 100)
svm <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1)
set.seed(26)
x = matrix(rnorm(200*2), ncol = 2)
x[1: 100, ] = x[1:100, ] + 2
x[101: 150, ] = x[101: 150, ] + 2
y <- c(rep(1, 150), rep(2, 50))
df <- data.frame(x, as.factor(y))
plot(x, col = y)
train <- sample(200, 100)
svm <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1)
library(e1071)
svm <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1)
df <- data.frame(x, as.factor(y))
df
df <- data.frame(x = x, y = as.factor(y))
df
svm <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1)
plot(svm, df[train, ])
summary(svm)
svm_2 <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1e5)
summary(svm_2)
plot(svm_2, df[train, ])
tune <- tune(svm, y ~ ., data = df[train, ], kernel = 'radial',
ranges = list(cost = c(0.1, 1, 10, 100, 1000)),
gamma = c(0.5, 1, 2, 3, 4))
library(e1071)
set.seed(26)
x = matrix(rnorm(200*2), ncol = 2)
x[1: 100, ] = x[1:100, ] + 2
x[101: 150, ] = x[101: 150, ] + 2
y <- c(rep(1, 150), rep(2, 50))
df <- data.frame(x = x, y = as.factor(y))
train <- sample(200, 100)
tune <- tune(svm, y ~ ., data = df[train, ], kernel = 'radial',
ranges = list(cost = c(0.1, 1, 10, 100, 1000)),
gamma = c(0.5, 1, 2, 3, 4))
summary(tune)
tune_pred <- predict(tune$best.model, df[-train, ])
table(tune_pred, df[-train, ]$y)
library(ROCR)
install.packages('ROCR')
library(ROCR)
recplot <- function(pred, truth, ...){
predob <- prediction(pred, truth)
pref <- performance(predob, 'tpr', 'fpr')
plot(perf, ...)
}
svm_2 <- svm(y ~ ., data = df[train, ], kernel = 'radial',
gamma = 1, cost = 1, decision.value = T)
predict_2 <- predict(svm_2, df[train, ], decision.values = T)
fit <- attributes(predict_2)$decision.values
fit
par(mfrow = c(1, 2))
rocplot <- function(pred, truth, ...){
predob <- prediction(pred, truth)
pref <- performance(predob, 'tpr', 'fpr')
plot(perf, ...)
}
rocplot(fit, df[train, 'y'], main = 'Training Data')
set.seed(654)
x <- rbind(x, matrix(rnorm(50*2), ncol = 2))
y <- c(y, rep(0, 50))
x[y == 0, 2] = x[y == 0, 2] + 2
df <- data.frame(x = x, y = as.factor(y))
df
plot(x, col = (y + 1))
svm_3 <- svm(y ~ ., data = df, kernel = 'radial', cost = 10,
gamma = 1)
plot(svm_3, df)
library(ISLR)
names(Khan)
head(Khan)
names(Khan)
str(Khan$xtrain)
str(Khan$xtest)
str(Khan$ytrain)
str(Khan$ytest)
df_gene <- data.frame(x = Khan$xtrain, y = as.factor(Khan$ytrain))
svm_gene <- svm(y ~ ., df_gene, kernel = 'linear', cost = 10)
summary(svm_gene)
summary(svm_3)
summary(svm_gene)
table(svm_gene$fitted, df_gene$y)
df_gene_test <- data.frame(x = Khan$xtest,
y = as.factor(Khan$ytest))
gene_pred <- predict(svm_gene, newdata = df_gene_test)
table(gene_pred, df_gene_test$y)
install.packages('rjson')
getwd()
setwd("~/R/learn_R_the_hard_way/packages/json")
list.files()
json <- fromJSON('wea.json')
library(rjson)
json <- fromJSON('wea.json')
install.packages('jsonlite')
library(jsonlite)
json <- fromJSON('wea.json')
json
class(json)
head(json)
?fromJSON
json <- fromJSON('wea.json', pretty = T)
names(json)
json$date
str(json)
install.packages('RJSONIO')
library(RJSONIO)
json
json <- fromJSON('wea.json')
json
?fromJSON
json <- fromJSON('wea.json', encoding = 'utf-8')
json
json <- fromJSON('wea.json', encoding = 'unicode')
json <- fromJSON('wea.json', encoding = 'UTF8')
json
